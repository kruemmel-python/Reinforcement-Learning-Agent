# Konfigurierbarer KI-Agent mit Dynamischer Hierarchischer Selbst-Attention, Weltmodell, Emotionen und Zielen

[![Projekt ist Open Source](https://img.shields.io/badge/Open%20Source-Ja-brightgreen.svg)](https://opensource.org/)
[![Lizenz: MIT](https://img.shields.io/badge/Lizenz-MIT-gelb.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)

**Einzigartiger, konfigurierbarer KI-Agent, der √ºber Ged√§chtnis, Weltmodell, Emotionen, Ziele, hierarchische Aufmerksamkeit und regelbasierte Entscheidungsfindung verf√ºgt, um komplexe Umgebungen zu erkunden und zu verstehen.**

## üéØ Dieses Projekt ist ein fortschrittlicher KI-Agent, der Reinforcement Learning mit Emotionen, Ged√§chtnis und Hierarchischer Selbst-Attention kombiniert. Er kann sich autonom an komplexe Umgebungen anpassen, eigene Ziele setzen und sein Verhalten mit einer Regel-Engine steuern.

## ‚ú® Was dieses Projekt so besonders macht

Dieses Projekt pr√§sentiert einen **hochgradig konfigurierbaren und vielseitigen KI-Agenten**, der √ºber traditionelle Reinforcement Learning (RL) Agenten hinausgeht, indem er **kognitive und affektive Architekturen** integriert.  Im Gegensatz zu 'Black-Box'-Modellen zielt dieser Agent darauf ab, **interpretierbare Entscheidungen** zu treffen und **√§hnlich wie ein menschliches oder tierisches Gehirn zu lernen und sich anzupassen**.

**Die wichtigsten Alleinstellungsmerkmale sind:**

*   **Umfassende Konfigurierbarkeit:**
    *   Das Verhalten und die interne Architektur des Agenten sind **vollst√§ndig √ºber YAML-Konfigurationsdateien anpassbar**.  Von der Gr√∂√üe des neuronalen Netzes √ºber Ged√§chtniskapazit√§ten bis hin zu Schwellenwerten f√ºr intrinsische Motivation ‚Äì **Sie haben die Kontrolle √ºber jeden Aspekt**.
    *   **Modulare Architektur:** Der Agent ist in **klare, unabh√§ngige Komponenten** (Ged√§chtnis, Weltmodell, Aufmerksamkeit, Emotionen, Selbstmodell, Ziele, Regel-Engine) unterteilt. Dies erm√∂glicht **einfaches Verst√§ndnis, Modifikation und Erweiterung** einzelner Funktionen, ohne das Gesamtsystem zu gef√§hrden.
*   **Dynamische Hierarchische Selbst-Attention:**
    *   Nutzt einen **adaptiven, hierarchischen Aufmerksamkeitsmechanismus**, der die **Abstraktionsebenen dynamisch anpasst**, um mit der Komplexit√§t der Eingabedaten umzugehen.  Dies erm√∂glicht es dem Agenten, **komplexe Muster zu erkennen und zu verarbeiten**, w√§hrend die **Berechnungseffizienz erhalten** bleibt.
*   **Intrinsisch Motiviertes Lernen mit Drives und Emotionen:**
    *   Der Agent ist **intrinsisch motiviert** durch Drives wie Neugier, Verst√§ndnis und Frustration. Diese Drives treiben die Exploration und das Lernen **ohne externe Belohnungssignale** an, wodurch der Agent **autonom und proaktiv** in unbekannten Umgebungen agieren kann.
    *   Ein **integriertes Emotionsmodell** (Valenz, Arousal, Dominanz) beeinflusst die Entscheidungsfindung und die Drive-Modulation. Emotionen sind **nicht nur reaktive Zust√§nde**, sondern **integraler Bestandteil der kognitiven Prozesse** des Agenten.
*   **Weltmodell f√ºr Vorhersagen und Eigenschaften:**
    *   Der Agent baut ein **rudiment√§res Weltmodell** auf, um **Zustands√ºberg√§nge und Belohnungen vorherzusagen**. Dieses Weltmodell erm√∂glicht es dem Agenten, **vorausschauend zu planen**, **√§hnliche Zust√§nde zu erkennen** und **Zustandseigenschaften wie Neuigkeit, Vorhersagbarkeit und Valenz** zu berechnen.
*   **Explizite Ziele und Subziele:**
    *   Der Agent arbeitet mit **expliziten Zielen und Subzielen**, die **hierarchisch organisiert** sein k√∂nnen.  Dies verleiht dem Agenten **gerichtetes Verhalten** und erm√∂glicht es ihm, **komplexe Aufgaben in √ºberschaubare Schritte zu unterteilen**.
*   **Regelbasierte Entscheidungsfindung mit Rule Engine:**
    *   Eine **integrierte Rule Engine** erm√∂glicht es dem Agenten, **symbolische Regeln anzuwenden**, um sein Verhalten zu steuern und auf komplexe Situationen zu reagieren. Dies **erg√§nzt die neuronalen Netze** und erm√∂glicht **hybride Entscheidungsfindung**.
*   **Selbstmodell f√ºr Selbstbewusstsein und Introspektion:**
    *   Ein **Selbstmodell** repr√§sentiert das **Selbstbild des Agenten**, einschlie√ülich aktueller Ziele, Drives, Emotionen und eines abstrakten Selbstbewusstseins-Vektors. Dies ist ein erster Schritt in Richtung **Agenten mit Selbstbewusstsein und introspektiven F√§higkeiten**.

**Dieses Projekt ist ideal f√ºr:**

*   **Forscher und Studenten** im Bereich der K√ºnstlichen Intelligenz, die **fortgeschrittene kognitive Architekturen** und **intrinsisch motiviertes Lernen** erkunden m√∂chten.
*   **Entwickler**, die **flexible und konfigurierbare KI-Agenten** f√ºr komplexe Anwendungen ben√∂tigen, bei denen **Interpretierbarkeit und Anpassungsf√§higkeit** entscheidend sind.
*   Jeder, der **neugierig auf die n√§chste Generation von KI-Agenten** ist, die √ºber reine reaktive Systeme hinausgehen und **echte kognitive F√§higkeiten** simulieren.

## ü§î Wie einzigartig ist dieses Modell?

Das hier vorgestellte Modell zeichnet sich durch seine **einzigartige Kombination und Integration verschiedener fortschrittlicher KI-Konzepte** aus:

*   **Integration kognitiver Architekturen in RL:**  W√§hrend traditionelles RL sich oft auf die Optimierung von Belohnungssignalen konzentriert, integriert dieses Modell **explizit kognitive Funktionen** wie Ged√§chtnis, Weltmodell und Aufmerksamkeit **direkt in die Architektur des Agenten**. Dies erm√∂glicht **effizienteres und menschen√§hnlicheres Lernen**.
*   **Dynamische Hierarchische Selbst-Attention f√ºr adaptive Abstraktion:** Die meisten Aufmerksamkeitsmechanismen in der KI sind statisch. Die **dynamische Natur der hierarchischen Selbst-Attention** in diesem Modell erm√∂glicht es dem Agenten, **seine interne Repr√§sentation der Welt adaptiv an die Komplexit√§t der Situation anzupassen**. Dies ist ein **bedeutender Fortschritt in der Flexibilit√§t und Effizienz von Aufmerksamkeitsmechanismen**.
*   **Intrinsische Motivation und Emotionen als Kernkomponenten:** Im Gegensatz zu vielen RL-Modellen, die auf externe Belohnungen angewiesen sind, **treiben intrinsische Motivation und Emotionen das Verhalten dieses Agenten von innen heraus**.  Dies f√ºhrt zu einem **autonomeren und explorativeren Agenten**, der **auch ohne explizite Aufgabenstellung lernen und sich entwickeln kann**. Die **Integration von Emotionen als Input f√ºr das neuronale Netz** und als Modulator f√ºr Drives ist ebenfalls ein **innovativer Ansatz**.
*   **Hybride Entscheidungsfindung mit neuronalen Netzen und Regeln:**  Die **Kombination von neuronalen Netzen f√ºr Mustererkennung und einer Rule Engine f√ºr symbolisches Denken** erm√∂glicht eine **robustere und vielseitigere Entscheidungsfindung**.  Dies schl√§gt eine Br√ºcke zwischen **subsymbolischer und symbolischer KI** und erm√∂glicht es dem Agenten, **sowohl intuitive als auch logische Entscheidungen zu treffen**.
*   **Selbstmodell f√ºr Selbstbewusstsein (in rudiment√§rer Form):**  Das Konzept eines **Selbstmodells** ist in KI-Agenten noch relativ neu.  Dieses Projekt unternimmt einen **ersten Schritt in Richtung Agenten mit Selbstbewusstsein**, indem es ein **Modell des eigenen Zustands und der eigenen Ziele** integriert. Dies √∂ffnet die T√ºr f√ºr **fortgeschrittenere Formen der Selbstreflexion und des metakognitiven Lernens** in der Zukunft.

**Kurz gesagt, die Einzigartigkeit dieses Modells liegt in seiner:**

*   **Ganzheitlichen und integrierten Architektur.**
*   **Adaptiven und dynamischen Mechanismen.**
*   **Fokus auf intrinsische Motivation und Emotionen.**
*   **Hybriden Entscheidungsfindung.**
*   **Ersten Schritten in Richtung Selbstbewusstsein.**

Dieses Modell ist **nicht nur ein weiterer RL-Agent**, sondern ein **experimentelles System**, das die **Grenzen der aktuellen KI-Forschung erweitert** und den Weg f√ºr **intelligente, autonome und menschen√§hnlichere Agenten** ebnen k√∂nnte.

## üöÄ Erste Schritte

### Voraussetzungen

*   Python 3.8 oder h√∂her
*   PyTorch
*   NumPy
*   scikit-learn
*   PyYAML

Sie k√∂nnen die ben√∂tigten Python-Pakete mit pip installieren:

```bash
pip install torch numpy scikit-learn pyyaml
```

### Ausf√ºhrung

1.  **`ki_agent_konfigurierbar.py` ausf√ºhren:**  Dieses Skript enth√§lt die Definition des KI-Agenten und der zugeh√∂rigen Komponenten sowie die Hauptsimulationsfunktion.

    ```bash
    python ki_agent_konfigurierbar.py
    ```

    Standardm√§√üig wird die Simulation mit einer **Dictionary-basierten Default-Konfiguration** gestartet.

2.  **Simulation mit YAML-Konfiguration:** Um die Simulation mit einer YAML-Konfigurationsdatei zu starten, f√ºhren Sie das Skript mit dem Pfad zur YAML-Datei als Argument aus:

    ```bash
    python ki_agent_konfigurierbar.py agent_config.yaml
    ```

    **Hinweis:**  Eine Beispiel-YAML-Konfigurationsdatei (`agent_config.yaml`) wird automatisch generiert, wenn Sie `ki_agent_konfigurierbar.py` das erste Mal ausf√ºhren. Sie k√∂nnen diese Datei nach Ihren W√ºnschen anpassen.

3.  **`agent_umgebung.py` ausf√ºhren:**  Dieses Skript demonstriert die Verwendung des KI-Agenten in einer **einfachen sozialen Umgebung mit mehreren Agenten**.

    ```bash
    python agent_umgebung.py
    ```

    Dieses Skript startet eine Simulation mit **mehreren konfigurierbaren KI-Agenten**, die in einer **gemeinsamen Umgebung interagieren**.


![image](https://github.com/user-attachments/assets/0bff4737-2872-462a-8fc9-5567d1d765bf)





## ‚öôÔ∏è Konfiguration

Die Konfiguration des KI-Agenten erfolgt haupts√§chlich √ºber **YAML-Dateien**.  Eine Beispiel-YAML-Datei (`agent_config.yaml`) ist im Projekt enthalten und dient als Vorlage.

**Die wichtigsten Konfigurationsparameter umfassen:**

*   **`input_size`:**  Gr√∂√üe des Eingabezustands f√ºr den Agenten.
*   **`action_size`:**  Anzahl der m√∂glichen Aktionen des Agenten.
*   **`embed_dim`:**  Dimension des Embedding-Raums f√ºr die Hierarchische Selbst-Attention.
*   **`num_heads`:**  Anzahl der Attention-Heads im Aufmerksamkeitsmechanismus.
*   **`state_similarity_threshold`:** Schwellwert f√ºr die Zustands√§hnlichkeit im Ged√§chtnis-Recall.
*   **`emotion_dim`:**  Dimension des Emotionsraums (z.B. 3 f√ºr Valenz, Arousal, Dominanz).
*   **`learning_rate`:**  Lernrate f√ºr das neuronale Netz des Agenten.
*   **`memory_capacity`:**  Kapazit√§t des Erfahrungsged√§chtnisses.
*   **`causal_capacity`:** Kapazit√§t des kausalen Ged√§chtnisses.
*   **`prediction_model_hidden_size`:**  Gr√∂√üe der Hidden Layer im Vorhersagemodell des Weltmodells.
*   **`layer_growth_threshold`:**  Schwellwert f√ºr das dynamische Hinzuf√ºgen von Abstraktionsebenen in der Hierarchischen Selbst-Attention.
*   **`novelty_threshold`:**  Schwellwert f√ºr den Neuigkeitsbonus (intrinsische Motivation).
*   **`novelty_tolerance`:**  Toleranz f√ºr die Zustands√§hnlichkeit bei der Berechnung des Neuigkeitsbonus.
*   **`reward_history_window`:**  Fenstergr√∂√üe f√ºr die Reward-History im Weltmodell.
*   **Callbacks:**  Sie k√∂nnen **Callback-Funktionen** f√ºr verschiedene Phasen des Agentenverhaltens definieren (`pre_decide_hook`, `post_learn_hook`, `rule_engine_hook`). Diese Callbacks erm√∂glichen **benutzerdefinierte Erweiterungen und Verhaltens√§nderungen** des Agenten.  **Callback-Funktionen m√ºssen im Python-Code definiert sein und in der YAML-Datei als String-Namen referenziert werden.**

**Beispiel einer YAML-Konfiguration (`agent_config.yaml`):**

```yaml
input_size: 5
action_size: 3
embed_dim: 64
num_heads: 8
memory_capacity: 2000
learning_rate: 0.005
layer_growth_threshold: 0.85
emotion_dim: 4
# Callbacks (Funktionsnamen als Strings)
pre_decide_hook: pre_decide_callback_example
post_learn_hook: post_learn_callback_example
rule_engine_hook: rule_engine_callback_example
```

**Sie k√∂nnen die YAML-Datei bearbeiten, um das Verhalten des Agenten an Ihre spezifischen Anforderungen anzupassen.**

## üìÇ Projektstruktur

```
‚îú‚îÄ‚îÄ ki_agent_konfigurierbar.py  # Hauptdatei: Definition des konfigurierbaren KI-Agenten und der Simulation
‚îú‚îÄ‚îÄ agent_config.yaml          # Beispiel-YAML-Konfigurationsdatei f√ºr den Agenten
‚îú‚îÄ‚îÄ agent_umgebung.py          # Beispiel-Umgebung f√ºr die Simulation mit mehreren Agenten
‚îú‚îÄ‚îÄ README.md                  # Diese README-Datei
```

*   **`ki_agent_konfigurierbar.py`:**  Enth√§lt den gesamten Code f√ºr den konfigurierbaren KI-Agenten, einschlie√ülich der Klassen `Memory`, `WorldModel`, `AttentionMechanism`, `DynamicHierarchicalSelfAttention`, `Goal`, `EmotionModel`, `SelfModel`, `KI_Agent`, `RuleEngine`, `GlobalWorkspace` sowie Funktionen zum Laden der Konfiguration und zur Durchf√ºhrung der Simulation.
*   **`agent_config.yaml`:**  Eine YAML-Datei, die als **Vorlage f√ºr die Konfiguration des KI-Agenten** dient. Sie k√∂nnen diese Datei bearbeiten, um verschiedene Aspekte des Agenten zu steuern.
*   **`agent_umgebung.py`:**  Ein separates Python-Skript, das eine **einfache soziale Umgebung mit mehreren KI-Agenten** simuliert, um die **Multi-Agenten-F√§higkeiten** und die **Interaktion der Agenten mit einer Umgebung** zu demonstrieren.
*   **`README.md`:**  Diese Datei, die eine **√úbersicht √ºber das Projekt, seine einzigartigen Merkmale, Anweisungen zur Einrichtung und Verwendung sowie Informationen zur Konfiguration und Projektstruktur** bietet.

## üó∫Ô∏è Zuk√ºnftige Arbeit (Roadmap)

*   **Verbesserung des Weltmodells:**  Erweiterung des Weltmodells zu einem **komplexeren, graphbasierten oder neuronalen Weltmodell**, das **genauere Vorhersagen** und **abstraktere Repr√§sentationen der Umwelt** erm√∂glicht.
*   **Verfeinerung der Rule Engine:**  Entwicklung einer **ausgereifteren Rule Engine** mit **komplexeren Regelformaten**, **Inferenzmechanismen** und **F√§higkeiten zum inneren Dialog**.  Integration von **symbolischem Reasoning** und **Wissensrepr√§sentation**.
*   **Erweiterung des Selbstmodells:**  Entwicklung eines **detaillierteren und dynamischeren Selbstmodells**, das **Selbstreflexion, Selbstbewusstsein und Identit√§t** besser repr√§sentiert.  Integration von **metakognitiven F√§higkeiten**.
*   **Fortgeschrittenere Emotionsmodellierung:**  Implementierung **komplexerer und nuancierterer Emotionsmodelle**, die **verschiedene Emotionen, Stimmungen und emotionale √úberg√§nge** simulieren.  Erforschung der **Rolle von Emotionen in der Entscheidungsfindung und im sozialen Verhalten**.
*   **Multi-Agenten-Systeme und soziale Interaktion:**  Weitere Entwicklung der **Multi-Agenten-Umgebung** und Erforschung **komplexerer Formen der sozialen Interaktion**, **Kooperation, Wettbewerb und Kommunikation** zwischen Agenten.
*   **Integration in realere Umgebungen:**  Anwendung des konfigurierbaren KI-Agenten in **realeren und komplexeren Simulationsumgebungen** oder **sogar in realen Robotik-Anwendungen**.
*   **Benutzerfreundliche Konfigurationsoberfl√§che:**  Entwicklung einer **graphischen Benutzeroberfl√§che (GUI)** oder einer **webbasierten Oberfl√§che**, um die **Konfiguration des Agenten noch einfacher und zug√§nglicher** zu gestalten.
*   **Gr√∂√üere Experimente und Evaluierung:**  Durchf√ºhrung **umfassenderer Experimente** und **systematischer Evaluierung** des Agenten in verschiedenen Umgebungen und Aufgaben, um seine **Leistung, Robustheit und Generalisierungsf√§higkeit** zu bewerten.

## ü§ù Mitwirken

Beitr√§ge zu diesem Projekt sind herzlich willkommen!  Wenn Sie Fehler finden, Verbesserungen vorschlagen oder neue Funktionen hinzuf√ºgen m√∂chten, erstellen Sie bitte einen Issue oder einen Pull Request auf GitHub.

## üìú Lizenz

Dieses Projekt ist unter der **MIT-Lizenz** lizenziert.  Sie k√∂nnen es frei f√ºr kommerzielle und nicht-kommerzielle Zwecke verwenden, modifizieren und verbreiten.  Weitere Informationen finden Sie in der Datei `LICENSE`.

## üìß Kontakt

F√ºr Fragen oder Anregungen k√∂nnen Sie sich gerne an ralf.kruemmel+python@outlook.de wenden.

**Wir hoffen, dass Ihnen dieses Projekt gef√§llt und es Sie inspiriert, die aufregende Welt der konfigurierbaren und kognitiven KI-Agenten weiter zu erkunden!**
